
<!-- ## 超越容量的界限 -->

## Beyond capacity limits

<!-- 现代操作系统不使用分段还是有一定的道理的.
有[研究表明][interference], Google数据中心中的1000台服务器在7分钟内就运行了上千个不同的程序,
其中有的是巨大无比的家伙(Google内部开发程序的时候为了避免不同计算机上的动态库不兼容的问题,
用到的所有库都以静态链接的方式成为程序的一部分, 光是程序的代码段就有几百MB甚至上GB的大小,
感兴趣的同学可以阅读[这篇文章][warehouse scale computer]), 有的只是一些很小的测试程序. -->

There is some reason why modern operating systems do not use segmentation.
[Research][interference] shows that 1,000 servers in Google data centers ran thousands of different programs within 7 minutes.
Some of them are huge guys (when Google develops programs internally, in order to avoid the problem of incompatibility of dynamic libraries on different computers,
All libraries used become part of the program through static linking. The code segment of the program alone is hundreds of MB or even GB in size.
Interested students can read [this article][warehouse scale computer]), some are just some small test programs.

<!-- 让这些特征各异的程序都占用连续的存储空间并不见得有什么好处:
一方面, 那些巨大无比的家伙们在一次运行当中只会触碰到很小部分的代码,
其实没有必要分配那么多内存把它们全部加载进来;
另一方面, 小程序运行结束之后, 它占用的存储空间就算被释放了,
也很容易成为"碎片空洞" - 只有比它更小的程序才能把碎片空洞用起来.
分段机制的简单朴素, 在现实中也许要付出巨大的代价. -->

There is no benefit in letting these programs with different characteristics all occupy contiguous storage space:
On the one hand, those huge guys will only touch a small part of the code in a run.
In fact, there is no need to allocate so much memory to load them all;
On the other hand, after the mini program ends, the storage space it occupies is released.
It is also easy to become a "fragment hole" - only smaller programs can use the fragment hole.
The simplicity of the segmentation mechanism may come at a huge cost in reality.

[interference]: http://arcade.cs.columbia.edu/interference-sc12.pdf
[warehouse scale computer]: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44271.pdf

<!-- 事实上, 我们需要一种按需分配的虚存管理机制.
之所以分段机制不好实现按需分配, 就是因为段的粒度太大了,
为了实现这一目标, 我们需要反其道而行之:
把连续的存储空间分割成小片段, 以这些小片段为单位进行组织, 分配和管理.
这正是分页机制的核心思想. -->

In fact, we need a virtual memory management mechanism that allocates on demand.
The reason why the segmentation mechanism cannot achieve on-demand allocation is because the granularity of the segments is too large.
To achieve this, we need to do the opposite:
Divide the continuous storage space into small fragments, and organize, allocate and manage these small fragments as units.
This is the core idea of the paging mechanism.

<!-- ### 分页 -->
### Memory Paging

<!-- 在分页机制中, 这些小片段称为页面, 在虚拟地址空间和物理地址空间中也分别称为虚拟页和物理页.
分页机制做的事情, 就是把一个个的虚拟页分别映射到相应的物理页上.
显然, 这一映射关系并不像分段机制中只需要一个段基址寄存器就可以描述的那么简单.
分页机制引入了一个叫"页表"的结构, 页表中的每一个表项记录了一个虚拟页到物理页的映射关系,
来把不必连续的物理页面重新组织成连续的虚拟地址空间. -->

In the paging mechanism, these small fragments are called pages, which are also called virtual pages and physical pages in the virtual address space and physical address space respectively.
What the paging mechanism does is to map each virtual page to the corresponding physical page.
Obviously, this mapping relationship is not as simple as what can be described by only one segment base address register in the segmentation mechanism.
The paging mechanism introduces a structure called "page table". Each entry in the page table records the mapping relationship between a virtual page and a physical page, to reorganize physical pages that are not necessarily contiguous into contiguous virtual address space.

<!-- 因此, 为了让分页机制支撑多任务操作系统的运行, 操作系统首先需要以物理页为单位对内存进行管理.
每当加载程序的时候, 就给程序分配相应的物理页(注意这些物理页之间不必连续),
并为程序准备一个新的页表, 在页表中填写程序用到的虚拟页到这些物理页的映射关系.
等到程序运行的时候, 操作系统就把之前为这个程序填写好的页表设置到MMU中,
MMU就会根据页表的内容进行地址转换, 把程序的虚拟地址空间映射到操作系统所希望的物理地址空间上. -->

Therefore, in order for the paging mechanism to support the operation of a multi-tasking operating system, the operating system first needs to manage memory in units of physical pages.
Whenever a program is loaded, corresponding physical pages are allocated to the program (note that these physical pages do not have to be consecutive).
Prepare a new page table for the program, and fill in the mapping relationship between the virtual pages used by the program and these physical pages in the page table.
When the program runs, the operating system sets the page table previously filled in for the program into the MMU.
The MMU will perform address translation based on the contents of the page table, mapping the program's virtual address space to the physical address space desired by the operating system.

![os-paging](./images/Os-paging.png)

<!-- > #### question::虚存管理中PIC的好处
> 我们之前提到, PIC的其中一个好处是可以将代码加载到任意内存位置执行.
> 如果配合虚存管理, PIC还有什么新的好处呢? (Hint: 动态库已经在享受这些好处了) -->

> #### question::The benefits of PIC in virtual memory management
> We mentioned before that one of the benefits of PIC is that code can be loaded into any memory location for execution.
> If combined with virtual memory management, what new benefits does PIC have? (Hint: Dynamic libraries are already enjoying these benefits)

<!-- i386是x86史上首次引进分页机制的处理器, 它把物理内存划分成以4KB为单位的页面,
同时也采用了二级页表的结构.
为了方便叙述, i386给第一级页表取了个新名字叫"页目录".
虽然听上去很厉害, 但其实原理都是一样的.
每一张页目录和页表都有1024个表项, 每个表项的大小都是4字节,
除了包含页表(或者物理页)的基地址, 还包含一些标志位信息. -->

i386 is the first processor in x86 history to introduce a paging mechanism. It divides physical memory into pages in units of 4KB.
At the same time, the structure of the secondary page table is also adopted.
In order to facilitate the description, i386 gave the first-level page table a new name called "page directory".
Although it sounds amazing, the principle is actually the same.
Each page directory and page table has 1024 entries, and the size of each entry is 4 bytes.
In addition to containing the base address of the page table (or physical page), it also contains some flag information.

<!-- 因此, 一张页目录或页表的大小是4KB, 要放在寄存器中是不可能的, 因此它们要放在内存中.
为了找到页目录, i386提供了一个CR3(control register 3)寄存器, 专门用于存放页目录的基地址.
这样, 页级地址转换就从CR3开始一步一步地进行, 最终将虚拟地址转换成真正的物理地址,
这个过程称为一次page table walk. -->

Therefore, the size of a page directory or page table is 4KB, which is impossible to put in a register, so they have to be stored in memory.
In order to find the page directory, i386 provides a CR3 (control register 3) register, which is specially used to store the base address of the page directory.
In this way, page-level address translation is performed step by step starting from CR3, and finally the virtual address is converted into a real physical address.
This process is called a page table walk.
```
                                                              PAGE FRAME
              +-----------+-----------+----------+         +---------------+
              |    DIR    |   PAGE    |  OFFSET  |         |               |
              +-----+-----+-----+-----+-----+----+         |               |
                    |           |           |              |               |
      +-------------+           |           +------------->|    PHYSICAL   |
      |                         |                          |    ADDRESS    |
      |   PAGE DIRECTORY        |      PAGE TABLE          |               |
      |  +---------------+      |   +---------------+      |               |
      |  |               |      |   |               |      +---------------+
      |  |               |      |   |---------------|              ^
      |  |               |      +-->| PG TBL ENTRY  |--------------+
      |  |---------------|          |---------------|
      +->|   DIR ENTRY   |--+       |               |
         |---------------|  |       |               |
         |               |  |       |               |
         +---------------+  |       +---------------+
                 ^          |               ^
+-------+        |          +---------------+
|  CR3  |--------+
+-------+
```

<!-- 我们不打算给出分页过程的详细解释, 请你结合i386手册的内容和课堂上的知识,
尝试理解i386分页机制, 这也是作为分页机制的一个练习.
i386手册中包含你想知道的所有信息, 包括这里没有提到的表项结构, 地址如何划分等. -->

We are not going to give a detailed explanation of the paging process. Please combine the content of the i386 manual with the knowledge in the classroom.
Try to understand the i386 paging mechanism, which is also an exercise in paging mechanism.
The i386 manual contains all the information you want to know, including table entry structures not mentioned here, how addresses are divided, etc.

<!-- > #### question::理解分页细节
> * i386不是一个32位的处理器吗, 为什么表项中的基地址信息只有20位, 而不是32位?
> * 手册上提到表项(包括CR3)中的基地址都是物理地址, 物理地址是必须的吗? 能否使用虚拟地址?
> * 为什么不采用一级页表? 或者说采用一级页表会有什么缺点? -->

> #### question::Understanding paging details
> * Isn't i386 a 32-bit processor? Why does the base address information in the table entry only have 20 bits instead of 32 bits?
> * The manual mentions that the base addresses in the entries (including CR3) are physical addresses. Is the physical address necessary? Can I use a virtual address?
> * Why not use a first-level page table? Or what are the disadvantages of using a first-level page table?

<!-- 页级转换的过程并不总是成功的, 因为i386也提供了页级保护机制, 实现保护功能就要靠表项中的标志位了.
我们对一些标志位作简单的解释:
* present位表示物理页是否可用, 不可用的时候又分两种情况:
  1. 物理页面由于交换技术被交换到磁盘中了, 这就是你在课堂上最熟悉的Page fault的情况之一了,
     这时候可以通知操作系统内核将目标页面换回来, 这样就能继续执行了
  1. 进程试图访问一个未映射的线性地址, 并没有实际的物理页与之相对应, 因此这就是一个非法操作咯
* R/W位表示物理页是否可写, 如果对一个只读页面进行写操作, 就会被判定为非法操作
* U/S位表示访问物理页所需要的权限, 如果一个ring 3的进程尝试访问一个ring 0的页面, 当然也会被判定为非法操作 -->

The process of page-level conversion is not always successful, because i386 also provides a page-level protection mechanism, and the protection function depends on the flag bit in the table entry.
We give a brief explanation of some flags:
* The present bit indicates whether the physical page is available. When it is not available, there are two situations:
   1. The physical page is swapped to the disk due to swapping technology. This is one of the Page fault situations you are most familiar with in class.
      At this time, you can notify the operating system kernel to change the target page back, so that execution can continue.
   1. The process attempts to access an unmapped linear address. There is no actual physical page corresponding to it, so this is an illegal operation.
* The R/W bit indicates whether the physical page is writable. If a read-only page is written, it will be judged as an illegal operation.
* The U/S bit indicates the permissions required to access the physical page. If a ring 3 process attempts to access a ring 0 page, it will of course be judged as an illegal operation.

<!-- > #### todo::理解分页机制
> 上文只介绍了i386的分页机制, 事实上, 其它ISA的分页机制也是大同小异,
> 理解了i386分页机制之后, mips32和riscv32的分页机制也就不难理解了.
>
> 当然, 具体细节还是得RTFM. -->

> #### todo::Understand the paging mechanism
> The above only introduces the paging mechanism of i386. In fact, the paging mechanisms of other ISAs are also similar.
> After understanding the i386 paging mechanism, the paging mechanisms of mips32 and riscv32 are not difficult to understand.
>
> Of course, the specific details still need to be RTFM.

<!-- -->
<!-- > #### comment::riscv64需要实现三级页表
> riscv32的Sv32机制只能对32位的虚拟地址进行地址转换, 但riscv64的虚拟地址最长是64位,
> 因此需要有另外的机制来支持更长的虚拟地址的地址转换.
> 在PA中, 如果你选择了riscv64, 那只需要实现Sv39三级页表的分页机制即可,
> 而且PA只会使用4KB小页面, 不会使用2MB的大页面, 因此你无需实现Sv39的大页面功能.
> 具体细节请RTFM. -->

> #### comment::riscv64 needs to implement a three-level page table
> The Sv32 mechanism of riscv32 can only perform address translation on 32-bit virtual addresses, but the longest virtual address of riscv64 is 64 bits.
> Therefore, another mechanism is needed to support address translation for longer virtual addresses.
> In PA, if you choose riscv64, you only need to implement the paging mechanism of Sv39 three-level page table.
> Moreover, PA will only use 4KB small pages and will not use 2MB large pages, so you do not need to implement the large page function of Sv39.
> Please RTFM for specific details.

<!-- -->
<!-- > #### question::空指针真的是"空"的吗?
> 程序设计课上老师告诉你, 当一个指针变量的值等于NULL时, 代表空, 不指向任何东西.
> 仔细想想, 真的是这样吗? 当程序对空指针解引用的时候, 计算机内部具体都做了些什么?
> 你对空指针的本质有什么新的认识? -->

> #### question::Is a null pointer really "null"?
> The teacher in the programming class told you that when the value of a pointer variable is equal to NULL, it means empty and does not point to anything.
> Think about it carefully, is this really the case? When the program dereferences the null pointer, what exactly is done inside the computer?
> What new insights do you have about the nature of null pointers?

<!-- 和分段机制相比, 分页机制更灵活, 甚至可以使用超越物理地址上限的虚拟地址.
现在我们从数学的角度来理解这两点.
撇去存储保护机制不谈, 我们可以把这分段和分页的过程分别抽象成两个数学函数: -->

Compared with the segmentation mechanism, the paging mechanism is more flexible and can even use virtual addresses that exceed the upper limit of physical addresses.
Now we understand these two points from a mathematical perspective.
Leaving aside the storage protection mechanism, we can abstract the segmentation and paging processes into two mathematical functions:
```
  y = seg(x) = seg.base + x
  y = page(x)
```

<!-- 可以看到, `seg()`函数只不过是做加法.
如果仅仅使用分段机制, 我们还要求段级地址转换的结果不能超过物理地址上限: -->

As you can see, the `seg()` function just does addition.
If only the segmentation mechanism is used, we also require that the result of segment-level address translation cannot exceed the upper limit of the physical address:
```
   y = seg(x) = seg.base + x < PMEM_MAX
=> x < PMEM_MAX - seg.base
=> x <= PMEM_MAX
```

<!-- 我们可以得出这样的结论: 仅仅使用分段机制, 虚拟地址是无法超过物理地址上限的.
而分页机制就不一样了, 我们无法给出`page()`具体的解析式,
是因为填写页目录和页表实际上就是在用枚举自变量的方式定义`page()`函数,
这就是分页机制比分段机制灵活的根本原因. -->

We can draw this conclusion: using only the segmentation mechanism, the virtual address cannot exceed the physical address limit.
The paging mechanism is different. We cannot give a specific parsing formula for `page()`.
This is because filling in the page directory and page table is actually defining the `page()` function by enumerating independent variables.
This is the fundamental reason why the paging mechanism is more flexible than the segmentation mechanism.

<!-- 虽然"页级地址转换结果不能超过物理地址上限"的约束仍然存在,
但我们只要保证每一个函数值都不超过物理地址上限即可,
并没有对自变量的取值作明显的限制, 当然自变量本身也就可以比函数值还大.
这就已经把分页的"灵活"和"允许使用超过物理地址上限"这两点特性都呈现出来了. -->

Although the constraint that "the page-level address translation result cannot exceed the upper limit of the physical address" still exists,
But we only need to ensure that each function value does not exceed the upper limit of the physical address.
There is no obvious restriction on the value of the independent variable. Of course, the independent variable itself can be larger than the function value.
This has already demonstrated the two characteristics of "flexibility" of paging and "allowing the use of more than the upper limit of the physical address".

<!-- i386采用段页式存储管理机制.
不过仔细想想, 这只不过是把分段和分页结合起来罢了, 用数学函数来理解, 也只不过是个复合函数: -->

i386 adopts segment page storage management mechanism.
But if you think about it carefully, this is just a combination of segmentation and paging. If you use a mathematical function to understand it, it is just a composite function:
```
paddr = page(seg(vaddr))
```

<!-- 而"虚拟地址空间"和"物理地址空间"这两个在操作系统中无比重要的概念,
也只不过是这个复合函数的定义域和值域而已. -->

"Virtual address space" and "physical address space" are two extremely important concepts in operating systems.
It is nothing more than the domain and value range of this composite function.

<!-- 最后, 支持分页机制的处理器能识别什么是页表吗?
我们以一个页面大小为1KB的一级页表的地址转换例子来认识这个问题: -->

Finally, can a processor that supports paging recognize what a page table is?
Let’s understand this problem with an example of address translation of a first-level page table with a page size of 1KB:
```c
pa = (pg_table[va >> 10] & ~0x3ff) | (va & 0x3ff);
```

<!-- 可以看到, 处理器并没有表的概念: 地址转换的过程只不过是一些访存和位操作而已.
这再次向我们展示了计算机的本质:
一堆美妙的, 蕴含着深刻数学智慧和工程原理的... 门电路!
然而这些小小的门电路操作却成为了今天多任务操作系统的根基,
支撑着千千万万程序的运行, 归根到底还是离不开计算机系统抽象的核心思想. -->

It can be seen that the processor does not have the concept of a table: the process of address translation is nothing more than some memory access and bit operations.
This again shows us the nature of computers:
A bunch of wonderful gates and circuits that contain profound mathematical wisdom and engineering principles!
However, these small gate operations have become the foundation of today's multi-tasking operating systems.
Supporting the operation of thousands of programs, in the final analysis, it is still inseparable from the core idea of ​​computer system abstraction.

<!-- ### 状态机视角下的虚存管理机制 -->

### Virtual memory management mechanism from the perspective of state machine

<!-- 从状态机视角来看, 虚存管理机制是什么呢? -->

From a state machine perspective, what is the virtual memory management mechanism?

<!-- 为了描述虚存管理机制在状态机视角的行为, 我们需要对状态机`S = <R, M>`的访存行为进行扩展.
具体地, 我们需要增加一个函数`fvm: M -> M`, 它就是我们上文讨论的地址转换的映射,
然后把状态机中所有对`M`的访问`M[addr]`替换成`M[fvm(addr)]`, 就是虚存管理机制的行为.
例如指令`mov $1, addr`, 在虚存机制关闭时, 它的行为是TRM定义的: -->

In order to describe the behavior of the virtual memory management mechanism from the state machine perspective, we need to extend the memory access behavior of the state machine `S = <R, M>`.
Specifically, we need to add a function `fvm: M -> M`, which is the mapping of the address translation we discussed above.
Then replace all accesses to `M` in the state machine `M[addr]` with `M[fvm(addr)]`, which is the behavior of the virtual memory management mechanism.
For example, the instruction `mov $1, addr`, when the virtual memory mechanism is turned off, its behavior is defined by TRM:
```
M[addr] <- 1
```
<!-- 而在虚存机制打开时, 它的行为则是: -->

When the virtual memory mechanism is turned on, its behavior is:
```
M[fvm(addr)] <- 1
```

<!-- 我们刚才已经讨论过, 地址转换的过程可以通过访存和位操作来实现,
这说明`fvm()`函数的行为也是可以通过状态机视角来描述的. -->

We have just discussed that the process of address translation can be achieved through memory access and bit operations.
This shows that the behavior of the `fvm()` function can also be described from a state machine perspective.

![vme](./images/vme.png)

<!-- 比较特殊的是`fvm()`这个函数. 回顾PA3介绍的状态机模型中引入的`fex()`函数,
它实际上并不属于状态机的一部分, 因为抛出异常的判断方式是和状态机的具体状态无关的.
而`fvm()`函数则有所不同, 它可以看做是是状态机的一部分,
这是因为`fvm()`函数是可以通过程序进行修改的: 操作系统可以决定如何建立虚拟地址和物理地址之间的映射.
具体地, `fvm()`函数可以认为是系统寄存器`SR`的一部分, 操作系统通过修改`SR`来对虚存进行管理. -->

What is more special is the function `fvm()`. Looking back at the `fex()` function introduced in the state machine model introduced in PA3,
It is not actually part of the state machine, because the way to judge whether an exception is thrown has nothing to do with the specific state of the state machine.
The `fvm()` function is different. It can be regarded as part of the state machine.
This is because the `fvm()` function is programmable: the operating system can decide how to establish the mapping between virtual addresses and physical addresses.
Specifically, the `fvm()` function can be considered as part of the system register `SR`, and the operating system manages virtual memory by modifying `SR`.

<!-- ### TLB - 地址转换的加速 -->

### TLB - Acceleration of address translation

<!-- 细心的你会发现, 在不改变页目录基地址, 页目录和页表的情况下,
如果连续访问同一个虚拟页的内容, 页级地址转换的结果都是一样的.
事实上, 这种情况太常见了, 例如程序执行的时候需要取指令,
而指令的执行一般都遵循局部性原理, 大多数情况下都在同一个虚拟页中执行.
但进行page table walk是要访问内存的, 如果有方法可以避免这些没有必要的page table walk,
就可以提高处理器的性能了. -->

If you are careful, you will find that without changing the page directory base address, page directory and page table, the contents of the same virtual page are accessed continuously, the results of page-level address translation will be the same.
In fact, this situation is too common. For example, when a program needs to fetch instructions,
The execution of instructions generally follows the principle of locality, and in most cases is executed in the same virtual page.
But performing a page table walk requires accessing memory. If there is a way to avoid these unnecessary page table walks,
This can improve the performance of the processor.

<!-- 一个很自然的想法就是将页级地址转换的结果存起来,
在进行下一次的页级地址转换之前, 看看这个虚拟页是不是已经转换过了,
如果是, 就直接取出之前的结果, 这样就可以节省不必要的page table walk了.
这不正好是cache的思想吗? 这样一个特殊的cache, 叫TLB.
我们可以从CPU cache的知识来理解TLB的组织: -->

A natural idea is to store the results of page-level address translation.
Before performing the next page-level address translation, check whether the virtual page has been translated.
If so, just retrieve the previous results directly, thus saving unnecessary page table walks.
Isn't this exactly the idea of cache? Such a special cache is called TLB.
We can understand the organization of TLB from the knowledge of CPU cache:

<!-- * TLB的基本单元是项, 一项存放了一次页级地址转换的结果
(其实就是一个页表项, 包括物理页号和一些和物理页相关的标志位), 功能上相当于一个cache block.
* TLB项的tag由虚拟页号来充当, 表示这一项对应于哪一个虚拟页号.
* TLB的项数一般不多, 为了提高命中率, TLB一般采用全相联或者组相联的组织方式.
* 由于页目录和页表一旦建立之后, 一般不会随意修改其中的表项, 因此TLB不存在写策略和写分配方式的问题. -->

* The basic unit of TLB is an item, which stores the result of a page-level address translation.
(In fact, it is a page table entry, including the physical page number and some flags related to the physical page), which is functionally equivalent to a cache block.
* The tag of the TLB item is acted by the virtual page number, indicating which virtual page number this item corresponds to.
* The number of TLB entries is generally small. In order to improve the hit rate, TLB generally adopts a fully associative or group associative organization method.
* Since once the page directory and page table are established, the entries in them are generally not modified at will, so the TLB does not have problems with write strategy and write allocation methods.

<!-- 实践表明, 大小64项的TLB, 命中率可以高达90%, 有了TLB之后, 果然大大节省了不必要的page table walk. -->

Practice has shown that the hit rate of a TLB of 64 entries can be as high as 90%. With the TLB, unnecessary page table walks are greatly saved.

<!-- 听上去真不错!
不过在现代的多任务操作系统中, 如果仅仅简单按照上述方式来使用TLB, 却会导致致命的后果.
我们知道, 操作系统会为每个进程分配不同的页目录和页表, 虽然两个进程可能都会从0x8048000开始执行,
但分页机制会把它们映射到不同的物理页, 从而做到存储空间的隔离.
当然, 操作系统进行进程切换的时候也需要更新CR3的内容,
使得CR3寄存器指向新进程的页目录, 这样才能保证分页机制将虚拟地址映射到新进程的物理存储空间. -->

Sounds really good!
However, in modern multi-tasking operating systems, simply using the TLB in the above manner will lead to fatal consequences.
We know that the operating system will allocate different page directories and page tables to each process, although both processes may start executing from 0x8048000.
However, the paging mechanism will map them to different physical pages to achieve storage space isolation.
Of course, the operating system also needs to update the contents of CR3 when switching processes.
Make the CR3 register point to the page directory of the new process, so as to ensure that the paging mechanism maps the virtual address to the physical storage space of the new process.

<!-- 现在问题来了, 假设有两个进程, 对于同一个虚拟地址0x8048000,
操作系统已经设置好正确的页目录和页表, 让1号进程映射到物理地址0x1234000,
2号进程映射到物理地址0x5678000, 同时假设TLB一开始所有项都被置为无效.
这时1号进程先运行, 访问虚拟地址0x8048000, 查看TLB发现未命中, 于是进行page table walk,
根据1号进程的页目录和页表进行页级地址转换, 得到物理地址0x1234000, 并填充TLB.
假设此时发生了进程切换, 轮到2号进程来执行, 它也要访问虚拟地址0x8048000, 查看TLB,
发现命中, 于是不进行page table walk, 而是直接使用TLB中的物理页号, 得到物理地址0x1234000.
2号进程竟然访问了1号进程的存储空间, 但2号进程和操作系统对此都毫不知情! -->

Here comes the problem, assuming there are two processes, for the same virtual address 0x8048000,
The operating system has set up the correct page directory and page table, allowing process No. 1 to be mapped to physical address 0x1234000.
Process No. 2 is mapped to physical address 0x5678000, and it is assumed that all entries in the TLB are invalidated at the beginning.
At this time, process No. 1 runs first, accesses the virtual address 0x8048000, checks the TLB and finds a miss, so the page table walk is performed.
Perform page-level address translation based on the page directory and page table of process No. 1, obtain the physical address 0x1234000, and fill the TLB.
Assume that a process switch occurs at this time, and it is the turn of process No. 2 to execute. It also needs to access the virtual address 0x8048000 and check the TLB.
A hit is found, so instead of performing a page table walk, the physical page number in the TLB is used directly to obtain the physical address 0x1234000.
Process No. 2 actually accessed the storage space of Process No. 1, but neither Process No. 2 nor the operating system knew about it!

<!-- 出现这个致命错误的原因是, TLB没有维护好进程和虚拟地址映射关系的一致性:
TLB只知道有一个从虚拟地址0x8048000到物理地址0x1234000的映射关系,
但它并不知道这个映射关系是属于哪一个进程的.
找到问题的原因之后, 解决它也就很容易了, 只要在TLB项中增加一个域ASID(address space ID),
用于指示映射关系所属的进程即可, mips32就是这样做的.
x86的做法则比较"野蛮", 在每次更新CR3时强制冲刷TLB的内容,
由于进程切换必定伴随着CR3的更新, 因此一个进程运行的时候, TLB中不会存在其它进程的映射关系.
当然, 为了防止冲刷过猛, 页表项中有一个Global位, 那些Global位为1的映射关系则不会被冲刷,
比如可以把内核中`do_syscall()`所在的页面的Global位设置为1,
这样系统调用的处理过程就不会出现TLB miss了. -->

The reason for this fatal error is that the TLB does not maintain the consistency between the virtual address mapping relationship and processes:
The TLB only knows that there is a mapping relationship from virtual address 0x8048000 to physical address 0x1234000.
But it doesn't know which process this mapping relationship belongs to.
After finding the cause of the problem, it is easy to solve it. Just add a domain ASID (address space ID) to the TLB entry.
It can be used to indicate the process to which the mapping relationship belongs. This is what mips32 does.
The x86 approach is more "barbaric", forcing the contents of the TLB to be flushed every time CR3 is updated.
Since process switching must be accompanied by CR3 updates, when one process is running, there will be no mapping relationship for other processes in the TLB.
Of course, in order to prevent excessive flushing, there is a Global bit in the page table entry, and those mapping relationships with a Global bit of 1 will not be flushed.
For example, you can set the Global bit of the page where `do_syscall()` is located in the kernel to 1,
In this way, TLB misses will not occur during system call processing.

<!-- ### 软件管理的TLB -->

### Software managed TLB

<!-- 对于x86和riscv32来说, TLB一般都是由硬件来负责管理的:
当TLB miss时, 硬件逻辑会自动进行page table walk, 并将地址转换结果填充到TLB中,
软件不知道也无需知道这一过程的细节.
对PA来说, 这是一个好消息: 既然对软件透明, 那么就可以简化了.
因此如果你选择了x86或者riscv32, 你不必在NEMU中实现TLB. -->

For x86 and riscv32, TLB is generally managed by hardware:
When the TLB misses, the hardware logic will automatically perform a page table walk and fill the address translation result into the TLB.
The software does not know and does not need to know the details of this process.
This is good news for PA: since it is transparent to the software, it can be simplified.
So if you choose x86 or riscv32, you don't have to implement the TLB in NEMU.

<!-- 但mips32就不一样了, 为了降低硬件设计的复杂度,
mips32规定, page table walk和TLB填充都由软件来负责.
很自然地, 在mips32中, TLB miss被设计成一种异常:
当TLB miss时, CPU将会抛出异常, 由软件来进行page table walk和TLB填充. -->

But mips32 is different. In order to reduce the complexity of hardware design,
Mips32 stipulates that both page table walk and TLB filling are responsible for software.
Naturally, in mips32, TLB miss is designed as an exception:
When the TLB misses, the CPU will throw an exception, and the software will perform page table walk and TLB filling.

<!-- 于是mips32需要把TLB的状态暴露给软件, 让软件可以来对TLB进行管理.
为了实现这一点, mips32至少需要添加以下内容:
* CP0寄存器, 包括entryhi, entrylo0, entrylo1, index这四个寄存器.
其中entryhi寄存器存放虚拟页号相关的信息, entrylo0寄存器和entrylo1寄存器存放物理页号相关的信息.
* CP0指令
  * tlbp, 用于寻找与entryhi寄存器中匹配的TLB项, 若找到, 则将index寄存器设置为该TLB项的序号
  * tlbwi, 用于将entryhi, entrylo0和entrylo1这三个寄存器的内容写入到index序号所指示的TLB项中
  * tlbwr, 用于将entryhi, entrylo0和entrylo1这三个寄存器的内容写入到随机一个TLB项中
  * 让mtc0和mfc0支持上述四个CP0寄存器的访问 -->

Therefore, mips32 needs to expose the status of the TLB to the software so that the software can manage the TLB.
In order to achieve this, mips32 needs to add at least the following:
* CP0 register, including entryhi, entrylo0, entrylo1, index.
The entryhi register stores information related to the virtual page number, and the entrylo0 register and entrylo1 register store information related to the physical page number.
* CP0 instruction
   * tlbp, used to find the TLB entry matching the entryhi register. If found, the index register is set to the serial number of the TLB entry.
   * tlbwi, used to write the contents of the three registers entryhi, entrylo0 and entrylo1 to the TLB entry indicated by the index sequence number
   * tlbwr, used to write the contents of the three registers entryhi, entrylo0 and entrylo1 to a random TLB entry
   * Let mtc0 and mfc0 support access to the above four CP0 registers

<!-- > #### question::mips32的TLB管理是否更简单?
> 有一种观点认为, mips32的分页机制更简单. 你认同吗?
> 尝试分别在现在, 以及完成这部分内容之后回答这个问题. -->

> #### question::Is TLB management simpler for MIPS32?
> Some argue that the paging mechanism of MIPS32 is simpler. Do you agree?
> Try to answer this question both now and after completing this part of the content.

<!-- TLB管理是一个考量软硬件tradeoff的典型例子,
mips32把这件事交给软件来做, 毫无疑问会引入额外的性能开销.
在一些性能不太重要的嵌入式场景中, 这并不会有什么大问题;
但如果是在一些面向高性能的场景中, 这种表面上简单的机制就成为了性能瓶颈的来源:
例如在数据中心场景中, 程序需要访问的数据非常多, 局部性也很差,
TLB miss是非常常见的现象, 这种情况下, 软件管理TLB的性能开销就会被进一步放大. -->

TLB management is a typical example of the tradeoff between software and hardware considerations. MIPS32 delegates this task to software, undoubtedly introducing additional performance overhead. In some embedded scenarios where performance is not crucial, this might not pose significant issues. However, in high-performance-oriented environments, this seemingly simple mechanism becomes a source of performance bottlenecks. For instance, in data center scenarios where programs access a vast amount of data with poor locality, TLB misses are common. In such cases, the performance overhead of software-managed TLB is further amplified.

<!-- 在mips32中, 为了进一步降低page table walk带来的性能开销,
一个TLB表项其实管理的是连续两个虚拟页面的映射关系,
于是物理页号相关的寄存器有entrylo0和entrylo1两个,
分别用于表示这两个虚拟页面对应的物理页号.
具体地, 假设虚拟地址和物理地址的长度都是32位, 并采用4KB页面大小,
那么entryhi寄存器中的虚拟页号则是19位, entrylo0和entrylo1寄存器中的物理页号为20位.
这样的好处是, 在一次page table walk中可以同时填充两个虚拟页面的地址转换结果,
期望通过程序的局部性获得一些性能收益.
不过在数据中心场景面前, 这都是杯水车薪了. -->

In MIPS32, to further reduce the performance overhead caused by page table walks, each TLB entry actually manages the mapping relationship between two contiguous virtual pages. Consequently, there are two registers related to physical page numbers: entrylo0 and entrylo1. They respectively represent the physical page numbers corresponding to these two virtual pages. Specifically, assuming both virtual and physical addresses are 32 bits long, and utilizing a 4KB page size, the virtual page number in the entryhi register is 19 bits, while the physical page numbers in the entrylo0 and entrylo1 registers are each 20 bits.
The advantage of this arrangement is that during a single page table walk, the address translation results for two virtual pages can be simultaneously filled, with the expectation of gaining some performance benefits through program locality. However, in the face of data center scenarios, these optimizations are merely drops in the bucket.

<!-- ## 将虚存管理抽象成VME -->

## Abstracting Virtual Memory Management into VME

<!-- 虚存管理的具体实现自然是架构相关的, 比如在x86中用于存放页目录基地址的CR3,
在riscv32上并不叫这个名字, 访问这个寄存器的指令自然也各不相同.
再者, 不同架构中的页面大小可能会有差异, 页表项的结构也不尽相同,
更不用说有的架构还可能有多于两级的页表结构了.
于是, 我们可以将虚存管理的功能划入到AM的一类新的API中,
名字叫VME(Virtual Memory Extension). -->

The specific implementation of virtual memory management naturally varies depending on the architecture. For instance, in x86, the control register CR3 is used to store the base address of the page directory, while on RISC-V32, it has a different name, and the instruction to access this register is also different. Furthermore, different architectures may have varying page sizes and page table entry structures, not to mention that some architectures may even have more than two levels of page table structures.
Therefore, we can categorize the functionality of virtual memory management into a new API under the umbrella of AM (Architecture Abstraction Layer), named VME (Virtual Memory Extension).

<!-- 老规矩, 我们来考虑如何将虚存管理的功能抽象成统一的API.
换句话说, 虚存机制的本质究竟是什么呢?
我们在上文已经讨论过这个问题了: 虚存机制, 说白了就是个映射(或函数).
也就是说, 本质上虚存管理要做的事情, 就是在维护这个映射.
但这个映射应该是每个进程都各自维护一份, 因此我们需要如下的两个API: -->

As usual, let's consider how to abstract the functionality of virtual memory management into a unified API.
In other words, what is the essence of the virtual memory mechanism?
We have already discussed this issue earlier: the virtual memory mechanism, simply put, is a mapping (or function).
That is to say, the fundamental task of virtual memory management is to maintain this mapping.
However, this mapping should be maintained separately by each process, so we need the following two APIs:

<!-- ```c
// 创建一个默认的地址空间
void protect(AddrSpace *as);

// 销毁指定的地址空间
void unprotect(AddrSpace *as);
``` -->

```c
// Create a default address space
void protect(AddrSpace *as);

// Destroy a default address space
void unprotect(AddrSpace *as);
```

<!-- 其中`AddrSpace`是一个结构体类型, 定义了地址空间描述符的结构(在`abstract-machine/am/include/am.h`中定义): -->

`AddrSpace` is a struct type that defines the structure of the address space descriptor (defined in `abstract-machine/am/include/am.h`):

```c
typedef struct AddrSpace {
  int pgsize;
  Area area;
  void *ptr;
} AddrSpace;
```
<!-- 其中`pgsize`用于指示页面的大小, `area`表示虚拟地址空间中用户态的范围,
`ptr`是一个ISA相关的地址空间描述符指针, 用于指示具体的映射. -->

The `pgsize` is used to indicate the size of the page, `area` represents the range of user mode in the virtual address space,
and `ptr` is an ISA-specific pointer to the address space descriptor, used to indicate the specific mapping.

<!-- 有了地址空间, 我们还需要有相应的API来维护它们. 于是很自然就有了如下的API: -->

With the address space established, we naturally need corresponding APIs to maintain them. Therefore, the following APIs are introduced:
```c
void map(AddrSpace *as, void *va, void *pa, int prot);
```
<!-- 它用于将地址空间`as`中虚拟地址`va`所在的虚拟页,
以`prot`的权限映射到`pa`所在的物理页.
当`prot`中的present位为`0`时, 表示让`va`的映射无效.
由于我们不打算实现保护机制, 因此权限`prot`暂不使用. -->

It is used to map the virtual page at the virtual address `va` within the address space `as`,
to the physical page at `pa`, with the permissions specified by `prot`.
When the present bit in `prot` is `0`, it means that the mapping for `va` is invalidated.
Since we do not plan to implement a protection mechanism, the `prot` permissions will not be used for now.

<!-- VME的主要功能已经通过上述三个API抽象出来了.
最后还有另外两个统一的API: -->

The main functions of Virtual Memory Environment (VME) have already been abstracted through the three APIs mentioned above.
Finally, there are two more unified APIs:

* `bool vme_init(void *(*pgalloc_f)(int), void (*pgfree_f)(void *))`
<!-- 用于进行VME相关的初始化操作. 其中它还接受两个来自操作系统的页面分配回调函数的指针,
让AM在必要的时候通过这两个回调函数来申请/释放一页物理页. -->

Used for VME-related initialization operations. It also accepts two pointers to page allocation callback functions from the operating system,
allowing the Abstract Machine (AM) to request/release a physical page when necessary through these two callback functions.

* `Context* ucontext(AddrSpace *as, Area kstack, void *entry)`
<!-- 用于创建用户进程上下文. 我们之前已经介绍过这个API, 但加入虚存管理之后,
我们需要对这个API的实现进行一些改动, 具体改动会在下文介绍. -->

Used to create user process contexts. We have previously introduced this API, but with the addition of virtual memory management,
some modifications need to be made to the implementation of this API, which will be detailed later.

<!-- 下面我们来介绍Nanos-lite如何使用VME提供的机制. -->

Next we will introduce how Nanos-lite uses the mechanism provided by VME.

<!-- ### 在分页机制上运行Nanos-lite -->

### Run Nanos-lite based on the paging mechanism

<!-- 由于页表位于内存中, 但计算机启动的时候, 内存中并没有有效的数据,
因此我们不可能让计算机启动的时候就开启分页机制.
操作系统为了启动分页机制, 首先需要准备一些内核页表.
框架代码已经为我们实现好这一功能了(见`abstract-machine/am/src/$ISA/nemu/vme.c`的`vme_init()`函数).
只需要在`nanos-lite/include/common.h`中定义宏`HAS_VME`,
Nanos-lite在初始化的时候首先就会调用`init_mm()`函数(在`nanos-lite/src/mm.c`中定义)来初始化MM.
这里的MM是指存储管理器(Memory Manager)模块, 它专门负责分页相关的存储管理. -->

Since the page table is located in memory, and at the time of computer startup, there is no valid data in memory,
it is not possible to enable the paging mechanism right at startup.
In order to start the paging mechanism, the operating system first needs to prepare some kernel page tables.
The framework code has already implemented this functionality for us (see the `vme_init()` function in `abstract-machine/am/src/$ISA/nemu/vme.c`).
You just need to define the macro `HAS_VME` in `nanos-lite/include/common.h`,
and Nanos-lite will first call the `init_mm()` function (defined in `nanos-lite/src/mm.c`) to initialize MM during its initialization.
Here, MM refers to the Memory Manager module, which is specifically responsible for paging-related storage management.


<!-- 目前初始化MM的工作有两项, 第一项工作是将TRM提供的堆区起始地址作为空闲物理页的首地址,
这样以后, 将来就可以通过`new_page()`函数来分配空闲的物理页了.
为了简化实现, MM可以采用顺序的方式对物理页进行分配, 而且分配后无需回收.
第二项工作是调用AM的`vme_init()`函数.
以riscv32为例, `vme_init()`将设置页面分配和回收的回调函数,
然后调用`map()`来填写内核虚拟地址空间(`kas`)的页目录和页表,
最后设置一个叫satp(Supervisor Address Translation and Protection)的CSR寄存器来开启分页机制.
这样以后, Nanos-lite就运行在分页机制之上了. -->

The initialization of the Memory Manager (MM) currently involves two main tasks. The first task is to use the heap start address provided by the TRM (Terminal Resource Manager) as the starting address for free physical pages. This setup allows the system to allocate free physical pages later through the `new_page()` function. To simplify the implementation, MM can sequentially allocate physical pages and does not require recycling after allocation.
The second task involves calling the `vme_init()` function from the Abstract Machine (AM). Taking riscv32 as an example, `vme_init()` sets up the callback functions for page allocation and release, then calls the `map()` function to populate the page directory and page tables for the kernel virtual address space (kas). Finally, it sets a CSR (Control and Status Register) called `satp` (Supervisor Address Translation and Protection) to enable the paging mechanism.
With these settings, Nanos-lite then operates on top of the paging system, which facilitates better management and protection of memory resources.

<!-- `map()`是VME中的核心API, 它需要在虚拟地址空间`as`的页目录和页表中填写正确的内容,
使得将来在分页模式下访问一个虚拟页(参数`va`)时, 硬件进行page table walk后得到的物理页,
正是之前在调用`map()`时给出的目标物理页(参数`pa`).
这再次体现了分页是一个软硬协同才能工作的机制: 如果`map()`没有正确地填写这些内容,
将来硬件进行page table walk的时候就无法取得正确的物理页. -->

The `map()` function is a core API within the Virtual Memory Environment (VME), and it plays a crucial role in setting up the virtual memory system. Its main function is to populate the page directory and page tables of the virtual address space `as` with the correct entries. This ensures that when a virtual page (specified by the parameter `va`) is accessed under paging mode, the hardware's page table walk will resolve to the exact physical page (specified by the parameter `pa`) that was defined during the `map()` call.
This underscores the collaborative nature of paging between software and hardware: if `map()` does not correctly populate the page tables and directory, the hardware will be unable to retrieve the correct physical page during the page table walk.

<!-- 对于x86和riscv32, `vme_init()`会通过`map()`来填写内核虚拟地址空间的映射.
这些映射十分特殊, 它们的`va`和`pa`是相同的, 我们将它们称为"恒等映射"(identical mapping).
在硬件开启分页机制之后, CPU访问的物理地址就跟分页机制关闭时相同,
从而在无需修改其它代码的情况下, 达到"Nanos-lite看起来像是直接运行在物理内存上"的效果.
建立这样一个映射也有利于Nanos-lite进行内存管理:
即使在分页模式下, Nanos-lite可以把内存的物理地址直接当做虚拟地址来访问,
访问的结果正好是相应的物理地址. -->

For x86 and riscv32, `vme_init()` uses `map()` to establish mappings in the kernel's virtual address space. These mappings are special because their virtual addresses (`va`) and physical addresses (`pa`) are the same, which are referred to as "identical mappings". After the hardware paging mechanism is activated, the physical addresses accessed by the CPU are the same as when the paging mechanism is disabled, allowing Nanos-lite to appear as if it is running directly on physical memory without needing to modify other code. Establishing such a mapping also facilitates memory management for Nanos-lite: even in paging mode, Nanos-lite can treat physical addresses as virtual addresses, and the addresses accessed will correspond exactly to the respective physical addresses.

<!-- 为了让`map()`填写的映射生效, 我们还需要在NEMU中实现分页机制.
具体地, 我们需要实现以下两点:
* 如何判断CPU当前是否处于分页模式?
* 分页地址转换的具体过程应该如何实现? -->

To ensure that the mappings created by `map()` are effective, we also need to implement the paging mechanism in NEMU. Specifically, we need to address the following two points:
* How to determine if the CPU is currently in paging mode?
* How should the address translation process of paging be implemented?

<!-- 但这两点都是ISA相关的, 于是NEMU将它们抽象成相应的API: -->

But these two points are related to ISA, so NEMU abstracts them into corresponding APIs:

<!-- ```c
// 检查当前系统状态下对内存区间为[vaddr, vaddr + len), 类型为type的访问是否需要经过地址转换.
int isa_mmu_check(vaddr_t vaddr, int len, int type);

// 对内存区间为[vaddr, vaddr + len), 类型为type的内存访问进行地址转换
paddr_t isa_mmu_translate(vaddr_t vaddr, int len, int type);
``` -->

```c
// Check whether memory access for the current system state within the range [vaddr, vaddr + len) and of type 'type' requires address translation.
int isa_mmu_check(vaddr_t vaddr, int len, int type);

// Perform address translation for memory access within the range [vaddr, vaddr + len) and of type 'type'.
paddr_t isa_mmu_translate(vaddr_t vaddr, int len, int type);
```

<!-- 为了使用这些API, 你需要对NEMU中虚拟地址访问的函数进行一些修改.
具体地, 首先需要通过`isa_mmu_check()`来根据当前的系统状态判断一次虚拟地址的访问应该如何进行:
* 如果`isa_mmu_check()`返回`MMU_DIRECT`, 表示可以直接把该地址作为物理地址来访问,
  此时直接调用`paddr_read()`或`paddr_write()`即可
* 如果`isa_mmu_check()`返回`MMU_TRANSLATE`, 表示该访问需要通过MMU进行地址转换,
  此时需要先调用`isa_mmu_translate()`进行地址转换,
  然后再通过地址转换后的物理地址来调用`paddr_read()`或`paddr_write()`
* 根据API的定义, `isa_mmu_check()`还可以返回`MMU_FAIL`,
  表示访问失败, 需要抛出异常, 不过这种情况在PA中不会出现 -->

To use these APIs, you need to modify the functions that handle virtual address access in NEMU.
Specifically, you first need to use `isa_mmu_check()` to determine how the virtual address access should proceed based on the current system state:
* If `isa_mmu_check()` returns `MMU_DIRECT`, it means that the address can be directly used as a physical address.
  In this case, simply call `paddr_read()` or `paddr_write()`.
* If `isa_mmu_check()` returns `MMU_TRANSLATE`, it indicates that the access requires address translation through the MMU.
  You should first call `isa_mmu_translate()` to perform the address translation,
  then use the translated physical address to call `paddr_read()` or `paddr_write()`.
* According to the API definition, `isa_mmu_check()` can also return `MMU_FAIL`,
  which means the access has failed and an exception should be thrown, although this situation will not occur in PA.

<!-- 如果你选择的是x86, 你需要添加CR3寄存器和CR0寄存器, 以及相应的操作它们的指令.
对于CR0寄存器, 我们只需要实现PG位即可. 如果发现CR0的PG位为1, 则说明CPU处于分页模式,
从此所有虚拟地址的访问都需要经过分页地址转换. -->

If you choose x86, you need to add the CR3 and CR0 registers, along with the instructions to operate them.
For the CR0 register, we only need to implement the PG bit. If the PG bit of CR0 is set to 1, it indicates that the CPU is in paging mode,
and from then on, all virtual address accesses must go through page address translation.

<!-- riscv32的Sv32分页机制和x86非常类似, 只不过寄存器的名字和页表项结构有所不同:
在riscv32中, 页目录基地址和分页使能位都是位于satp寄存器中.
至于页表项结构的差异, 这里就不详细说明了, 还是RTFM吧. -->

The Sv32 paging mechanism in RISCV32 is very similar to that of x86, with only differences in the names of the registers and the structure of the page table entries:
In RISC-V32, both the page directory base address and the paging enable bit are located in the `satp` register.
As for the differences in the structure of the page table entries, these are not detailed here; it is best to RTFM.

<!-- mips32的情况就大不一样了.
mips32简单地规定了虚拟地址空间的划分, 在PA中我们只会用到以下三段地址空间,
mips32还规定了其余空间的性质, 具体可查阅手册:
* `[0x80000000, 0xa0000000)`属于内核空间, 不进行地址转换
* `[0xa0000000, 0xb0000000)`属于I/O空间, 不进行地址转换
* `[0x00000000, 0x80000000)`属于用户空间, 需要进行地址转换 -->

The situation with MIPS32 is quite different.
MIPS32 simply specifies the division of the virtual address space. In PA, we will only use the following three segments of address space,
and MIPS32 also specifies the characteristics of the remaining spaces, which can be consulted in the manual:
* `[0x80000000, 0xa0000000)` belongs to kernel space, no address translation is performed.
* `[0xa0000000, 0xb0000000)` belongs to I/O space, no address translation is performed.
* `[0x00000000, 0x80000000)` belongs to user space, address translation is required.

<!-- 既然mips32的内核空间不需要进行地址转换, 那么就不需要维护所谓的内核映射了;
此外, mips32是以地址空间来决定是否需要进行地址转换,
那么也就不存在"分页机制是否开启"的状态了, 所以mips32中并没有类似CR0.PG这样的状态位.
所以`mips32-nemu`的`vme_init()`非常简单, 只需要注册页面管理的回调函数即可. -->

Since the kernel space in MIPS32 does not require address translation, there is no need to maintain what is called a kernel mapping.
Moreover, in MIPS32, whether address translation is needed is determined by the address space itself,
thus there is no "paging mechanism enabled" state, and therefore, MIPS32 does not have a status bit like CR0.PG.
As a result, the `vme_init()` in `mips32-nemu` is very simple, only requiring the registration of callback functions for page management.

<!-- 你需要理解分页地址转换的过程,
然后实现`isa_mmu_check()`(在`nemu/src/isa/$ISA/include/isa-def.h`中定义)
和`isa_mmu_translate()`(在`nemu/src/isa/$ISA/system/mmu.c`中定义),
你可以查阅NEMU的ISA相关API说明文档来了解它们的行为.
另外由于我们不打算实现保护机制, 在`isa_mmu_translate()`的实现中,
你务必使用assertion检查页目录项和页表项的present/valid位,
如果发现了一个无效的表项, 及时终止NEMU的运行, 否则调试将会非常困难.
这通常是由于你的实现错误引起的, 请检查实现的正确性. -->

You need to understand the process of page address translation,
then implement `isa_mmu_check()` (defined in `nemu/src/isa/$ISA/include/isa-def.h`)
and `isa_mmu_translate()` (defined in `nemu/src/isa/$ISA/system/mmu.c`).
You can refer to the NEMU ISA-related API documentation to understand their behavior.
Additionally, since we do not plan to implement a protection mechanism, in the implementation of `isa_mmu_translate()`,
you must use assertions to check the present/valid bits of the page directory entry and page table entry.
If an invalid entry is found, terminate the execution of NEMU immediately, otherwise debugging will be very difficult.
This is usually caused by errors in your implementation, please check the correctness of your implementation.

<!-- 最后提醒一下x86页级地址转换时出现的一种特殊情况.
由于x86并没有严格要求数据对齐, 因此可能会出现数据跨越虚拟页边界的情况,
例如一条很长的指令的首字节在一个虚拟页的最后, 剩下的字节在另一个虚拟页的开头.
如果这两个虚拟页被映射到两个不连续的物理页, 就需要进行两次页级地址转换,
分别读出这两个物理页中需要的字节, 然后拼接起来组成一个完成的数据返回.
不过根据KISS法则, 你现在可以暂时不实现这种特殊情况的处理,
在判断出数据跨越虚拟页边界的情况之后, 先使用`assert(0)`终止NEMU,
等到真的出现这种情况的时候再进行处理.
而mips32和riscv32作为RISC架构, 指令和数据都严格按照4字节对齐, 因此不会发生这样的情况,
否则CPU将会抛出异常, 可见软件灵活性和硬件复杂度是计算机系统中又一对tradeoff. -->

A final reminder about a special case that occurs with x86 page-level address translation.
Since x86 does not strictly require data alignment, data may cross virtual page boundaries.
For example, the first byte of a long instruction might be at the end of one virtual page, with the remaining bytes at the beginning of another virtual page.
If these two virtual pages are mapped to two non-contiguous physical pages, two page-level address translations are required,
to read the necessary bytes from each physical page and then concatenate them to form a complete data return.
However, according to the KISS principle, you can initially forego implementing this special case handling,
and use `assert(0)` to terminate NEMU upon detecting data crossing virtual page boundaries,
and handle it when such a situation actually arises.
In contrast, MIPS32 and RISC-V32, as RISC architectures, strictly align instructions and data to 4 bytes, so such scenarios do not occur,
otherwise, the CPU would throw an exception, illustrating yet another tradeoff between software flexibility and hardware complexity in computer systems.

<!-- > #### todo::在分页机制上运行Nanos-lite
> 实现以下内容:
> * Nanos-lite的`pg_alloc()`. `pg_alloc()`的参数是分配空间的字节数,
>   但我们保证AM通过回调函数调用`pg_alloc()`时申请的空间总是页面大小的整数倍,
>   因此可以通过调用`new_page()`来实现`pg_alloc()`.
>   此外`pg_alloc()`还需要对分配的页面清零.
> * VME的`map()`. 你可以通过`as->ptr`获取页目录的基地址.
>   若需要申请新的页表, 可以通过回调函数`pgalloc_usr()`向Nanos-lite获取一页空闲的物理页.
> * 在NEMU中实现分页机制.
>
> 由于此时Nanos-lite运行在内核的虚拟地址空间中, 而这些映射又是恒等映射,
> 因此NEMU的地址转换结果`pa`必定与`va`相同.
> 你可以把这一条件作为assertion加入到NEMU的代码中, 从而帮助你捕捉实现上的bug.
>
> 如果你的实现正确, 你会看到仙剑奇侠传也可以成功运行.
> 如果你对分页机制的细节有疑问, 请RTFM.
>
> 对于x86和riscv32, 你无需实现TLB.
>
> 对于mips32, 此时并不能检查你的实现是否正确, 这是因为在mips32中,
> 程序需要访问用户空间才会触发地址转换的过程.
> 因此如果你选择了mips32, 你需要完成下文的内容才能测试你的实现. -->

> #### todo::Run Nanos-lite on a paging mechanism
> Implement the following:
> * Nanos-lite's `pg_alloc()`. The parameter for `pg_alloc()` is the number of bytes to allocate,
>   but we ensure that AM calls `pg_alloc()` via callback function in multiples of page size,
>   thus, it can be implemented by calling `new_page()`.
>   Additionally, `pg_alloc()` needs to zero out the allocated pages.
> * VME's `map()`. You can obtain the base address of the page directory through `as->ptr`.
>   If a new page table is needed, you can get a free physical page from Nanos-lite via the callback function `pgalloc_usr()`.
> * Implement the paging mechanism in NEMU.
>
> Since Nanos-lite runs in the kernel's virtual address space and these mappings are identity mappings,
> the address translation result `pa` must be the same as `va`.
> You can use this condition as an assertion in the NEMU code to help catch implementation bugs.
>
> If your implementation is correct, you will see that the game Legend of Sword and Fairy can also run successfully.
> If you have questions about the details of the paging mechanism, please RTFM.
>
> For x86 and riscv32, you do not need to implement TLB.
>
> For mips32, at this point, you cannot check if your implementation is correct because in mips32,
> the process of address translation is only triggered when accessing user space.
> Therefore, if you have chosen mips32, you will need to complete the following content to test your implementation.

<!-- -->
<!-- > #### option::让DiffTest支持分页机制
> 为了让DiffTest机制正确工作, 你需要
> * 对于x86:
>   * 在`restart()`函数中我们需要对CR0寄存器初始化为`0x60000011`, 但我们不必关心其含义.
>   * 实现分页机制中accessed位和dirty位的功能
> * 处理`attach`命令时, 需要将分页机制相关的寄存器同步到REF中
> * 对快照功能进行更新
>
> 这毕竟是个选做题而已, 实现细节就不提示了, 遇到困难就自己思考一下解决方案吧.
>
> 但对于mips32来说, 引入的TLB也属于机器状态, 因此要完美地进行DiffTest,
> 则需要考虑如何将TLB同步到REF中. 这确实不是一件轻松的事情,
> 你可以思考一下如何解决, 不过放弃进行DiffTest也不失为一种解决方案. -->

> #### option::Enable DiffTest to support paging mechanism
> To make the DiffTest mechanism work correctly, you need:
> * For x86:
>   * In the `restart()` function, we need to initialize the CR0 register to `0x60000011`, but we do not need to concern ourselves with its meaning.
>   * Implement the functionality of the accessed and dirty bits in the paging mechanism.
> * When handling the `attach` command, synchronize the paging-related registers with REF.
> * Update the snapshot functionality.
>
> This is, after all, an optional exercise, and implementation details are not provided. If you encounter difficulties, consider solutions on your own.
>
> However, for mips32, the introduced TLB is also part of the machine state. Therefore, to perfectly perform DiffTest,
> it is necessary to consider how to synchronize the TLB with REF. This is indeed not an easy task,
> and you can think about how to solve it, though giving up on performing DiffTest could also be a viable solution.

<!-- -->
<!-- > #### comment::RISC-V的分页机制
> 如果你仔细RTFM, 你会发现标准RISC-V的分页机制需要在S模式及U模式下才能开启,
> 而在M模式下的访存并不会进行MMU的地址转换.
> 但我们在NEMU中进行了简化, 允许M模式的访存也进行地址转换,
> 这样可以避免引入S模式相关的细节, 让大家把注意力集中在分页机制本身. -->

> #### comment::RISC-V Paging Mechanism
> If you carefully RTFM, you will discover that the standard RISC-V paging mechanism can only be enabled in S-mode and U-mode,
> and memory access in M-mode does not undergo MMU address translation.
> However, in NEMU, we have simplified this by allowing address translation even in M-mode accesses,
> thus avoiding the introduction of S-mode related details and allowing everyone to focus on the paging mechanism itself.

<!--
### 地址转换的踪迹 - vmtrace

> #### todo::实现vmtrace
-->

<!-- ### 在分页机制上运行用户进程 -->
### Run user processes on a paging mechanism

<!-- 成功实现分页机制之后, 你会发现仙剑奇侠传也同样成功运行了.
但仔细想想就会发现这其实不太对劲:
我们在`vme_init()`中创建了内核的虚拟地址空间, 之后就再也没有切换过这一虚拟地址空间.
也就是说, 我们让仙剑奇侠传也运行在内核的虚拟地址空间之上!
这太不合理了, 毕竟用户进程还是应该有自己的一套虚拟地址空间.
更可况, Navy-apps之前让用户程序链接到`0x3000000`/`0x83000000`的位置,
是因为之前Nanos-lite并没有对空闲的物理内存进行管理;
现在引入了分页机制, 由MM来负责所有物理页的分配.
这意味着, 如果将来MM把`0x3000000`/`0x83000000`所在的物理页分配出去,
仙剑奇侠传的内容将会被覆盖(你之前在运行`exec-test`的时候已经遇到过这个问题了)!
因此, 目前仙剑奇侠传看似运行成功, 其实里面暗藏杀机. -->

After successfully implementing the paging mechanism, you may have noticed that the game "Chinese Paladin" also appears to run successfully. However, upon closer inspection, something seems off:
In `vme_init()`, we created a virtual address space for the kernel and never switched from it afterward. This means that "Chinese Paladin" is also running on top of the kernel's virtual address space!
This is quite unreasonable since user processes should have their own set of virtual address spaces. Furthermore, previously in Navy-apps, user programs were linked to positions at `0x3000000`/`0x83000000` because Nanos-lite did not manage free physical memory. Now with the introduction of the paging mechanism, the Memory Manager (MM) is responsible for allocating all physical pages. This means that if MM later allocates the physical pages at `0x3000000`/`0x83000000`, the content of "Chinese Paladin" will be overwritten (you have already encountered this issue while running the `exec-test`).
Therefore, although it seems like "Chinese Paladin" is running successfully, there are hidden dangers lurking within.

<!-- 正确的做法是, 我们应该让用户进程运行在操作系统为其分配的虚拟地址空间之上.
为此, 我们需要对工程作一些变动.
首先, 编译Navy应用程序的时候需要为`make`添加`VME=1`的参数,
这样就可以将应用程序的链接地址改为`0x40000000`,
这是为了避免用户进程的虚拟地址空间与内核相互重叠, 从而产生非预期的错误.
这时, "虚拟地址作为物理地址的抽象"这一好处已经体现出来了:
原则上用户进程可以运行在任意的虚拟地址, 不受物理内存容量的限制.
我们让用户进程的代码从`0x40000000`附近开始,
这个地址已经不在物理内存的地址空间中(NEMU提供的物理内存是128MB),
但分页机制保证了进程能够正确运行.
这样, 链接器和程序都不需要关心程序运行时刻具体使用哪一段物理地址,
它们只要使用虚拟地址就可以了, 而虚拟地址和物理地址之间的映射则全部交给操作系统的MM来管理. -->

The correct approach is to run the user process on the virtual address space allocated by the operating system.
To achieve this, we need to make some changes to the project.
First, when compiling the Navy application, you need to add the parameter `VME=1` to `make`. This will change the link address of the application to `0x40000000`. This is to avoid unexpected errors caused by the overlap between the virtual address space of the user process and the kernel.
At this point, the advantage of "virtual addresses as an abstraction of physical addresses" is already evident: in principle, the user process can run at any virtual address, regardless of the physical memory capacity.
We set the user process code to start near `0x40000000`. This address is already outside the physical memory address space (NEMU provides 128MB of physical memory), but the paging mechanism ensures that the process can run correctly.
Thus, neither the linker nor the program needs to worry about which physical address is actually used at runtime. They can simply use virtual addresses, and the mapping between virtual and physical addresses is entirely managed by the operating system's memory manager (MM).

<!-- 此外, 我们还需要对创建用户进程的过程进行较多的改动.
我们首先需要在加载用户进程之前为其创建地址空间.
由于地址空间是进程相关的, 我们将`AddrSpace`结构体作为PCB的一部分.
这样以后, 我们只需要在`context_uload()`的开头调用`protect()`, 就可以实现地址空间的创建.
目前这个地址空间除了内核映射之外就没有其它内容了,
具体可以参考`abstract-machine/am/src/$ISA/nemu/vme.c`. -->

Additionally, we need to make significant changes to the process of creating user processes. We first need to create an address space for the user process before loading it. Since the address space is process-related, we include the `AddrSpace` structure as part of the PCB. This way, we only need to call `protect()` at the beginning of `context_uload()` to create the address space. Currently, this address space contains nothing but the kernel mapping. For details, refer to `abstract-machine/am/src/$ISA/nemu/vme.c`.

<!-- 不过, 此时`loader()`不能直接把用户进程加载到内存位置`0x40000000`附近了,
因为这个地址并不在内核的虚拟地址空间中, 内核不能直接访问它.
`loader()`要做的事情是, 获取程序的大小之后, 以页为单位进行加载:
* 申请一页空闲的物理页
* 通过`map()`把这一物理页映射到用户进程的虚拟地址空间中.
  由于AM native实现了权限检查, 为了让程序可以在AM native上正确运行,
  你调用`map()`的时候需要将`prot`设置成可读可写可执行
* 从文件中读入一页的内容到这一物理页中 -->

However, at this point, `loader()` cannot directly load the user process near the memory location `0x40000000`, because this address is not in the kernel's virtual address space, and the kernel cannot directly access it. What `loader()` needs to do is to load the program in pages after determining its size:
* Allocate a free physical page.
* Use `map()` to map this physical page into the user process's virtual address space. Since AM native implements permission checks, to ensure the program can run correctly on AM native, you need to set `prot` to be readable, writable, and executable when calling `map()`.
* Read one page of content from the file into this physical page.


<!-- 这一切都是为了让用户进程在将来可以正确地运行: 用户进程在将来使用虚拟地址访问内存,
在loader为用户进程维护的映射下, 虚拟地址被转换成物理地址,
通过这一物理地址访问到的物理内存, 恰好就是用户进程想要访问的数据. -->

All of this is to ensure that the user process can run correctly in the future: the user process accesses memory using virtual addresses. Under the mapping maintained by the loader for the user process, virtual addresses are converted to physical addresses. The physical memory accessed through these physical addresses is exactly the data that the user process wants to access.

<!-- 另一个需要考虑的问题是用户栈, 和`loader()`类似,
我们需要把`new_page()`申请得到的物理页通过`map()`映射到用户进程的虚拟地址空间中.
我们把用户栈的虚拟地址安排在用户进程虚拟地址空间的末尾,
你可以通过`as.area.end`来得到末尾的位置,
然后把用户栈的物理页映射到`[as.area.end - 32KB, as.area.end)`这段虚拟地址空间. -->

Another issue to consider is the user stack. Similar to `loader()`, we need to map the physical page obtained by `new_page()` into the user process's virtual address space using `map()`. We place the virtual address of the user stack at the end of the user process's virtual address space. You can get the end position through `as.area.end`, and then map the physical page of the user stack to the virtual address space `[as.area.end - 32KB, as.area.end)`.

<!-- 最后, 为了让这一地址空间生效, 我们还需要将它落实到MMU中.
具体地, 我们希望在CTE恢复进程上下文的时候来切换地址空间.
为此, 我们需要将进程的地址空间描述符指针`as->ptr`加入到上下文中,
框架代码已经实现了这一功能(见`abstract-machine/am/include/arch/$ISA-nemu.h`),
在x86中这一成员为`cr3`, 而在mips32/riscv32中则为`pdir`. 你还需要
* 修改`ucontext()`的实现, 在创建的用户进程上下文中设置地址空间描述符指针
* 在`__am_irq_handle()`的开头调用`__am_get_cur_as()`
(在`abstract-machine/am/src/$ISA/nemu/vme.c`中定义),
来将当前的地址空间描述符指针保存到上下文中
* 在`__am_irq_handle()`返回前调用`__am_switch()`
(在`abstract-machine/am/src/$ISA/nemu/vme.c`中定义)来切换地址空间,
将被调度进程的地址空间落实到MMU中 -->

Finally, to make this address space effective, we need to apply it to the MMU. Specifically, we want to switch the address space when the CTE restores the process context. To do this, we need to add the process's address space descriptor pointer `as->ptr` to the context. The framework code has already implemented this feature (see `abstract-machine/am/include/arch/$ISA-nemu.h`). In x86, this member is `cr3`, while in mips32/riscv32 it is `pdir`. You also need to:
* Modify the implementation of `ucontext()` to set the address space descriptor pointer in the created user process context.
* Call `__am_get_cur_as()` at the beginning of `__am_irq_handle()` (defined in `abstract-machine/am/src/$ISA/nemu/vme.c`) to save the current address space descriptor pointer into the context.
* Call `__am_switch()` before `__am_irq_handle()` returns (defined in `abstract-machine/am/src/$ISA/nemu/vme.c`) to switch the address space, applying the address space of the scheduled process to the MMU.

<!-- > #### todo::为mips32实现真正的分页机制
> 如果你选择的是mips32, 现在你需要实现真正的分页机制了;
> 如果不是, 你可以忽略这道题.
>
> 当CPU尝试进行地址转换时, 若TLB发生miss,
> 硬件会将当前的虚拟页号设置到entryhi中, 然后抛出TLB refill异常.
> 这个异常会被CTE捕获, 然后调用`__am_tlb_refill()`函数:
> * 读出当前进程的页目录基地址(思考一下, 该如何获得?)
> * 从entryhi中读出虚拟页号
> * 根据虚拟页号进行page table walk
> * 将两个连续的虚拟页对应的物理页号设置到entrylo0和entrylo1中
> * 执行tlb管理的相关指令更新TLB表项
>
> 从TLB refill异常返回后, CPU会再次执行相同的指令, 这次的地址转换应该可以成功进行.
> 为了让软件来进行page table walk, 你需要实现`__am_tlb_refill()`
> (在`abstract-machine/am/src/mips32/nemu/vme.c`中定义).
>
> 根据上文内容, 我们还需要维护TLB表项和进程的关系, 这应该是通过ASID来完成的.
> 不过我们在这里可以进行简化, 参考x86, 我们也在切换地址空间的时候, 通过清空整个TLB来解决问题.
> 为此你还需要实现`__am_tlb_clear()`(在`abstract-machine/am/src/mips32/nemu/vme.c`中定义). -->

> #### todo::Implement the Real Paging Mechanism for mips32
> If you chose mips32, now you need to implement the real paging mechanism; if not, you can ignore this task.
>
> When the CPU tries to perform address translation and a TLB miss occurs, the hardware will set the current virtual page number in `entryhi` and then throw a TLB refill exception. This exception will be caught by the CTE, which will then call the `__am_tlb_refill()` function:
> * Read the page directory base address of the current process (think about how to obtain it).
> * Read the virtual page number from `entryhi`.
> * Perform a page table walk based on the virtual page number.
> * Set the physical page numbers corresponding to two consecutive virtual pages into `entrylo0` and `entrylo1`.
> * Execute the relevant TLB management instructions to update the TLB entries.
>
> After returning from the TLB refill exception, the CPU will re-execute the same instruction, and the address translation should succeed this time. To allow software to perform the page table walk, you need to implement `__am_tlb_refill()` (defined in `abstract-machine/am/src/mips32/nemu/vme.c`).
>
> According to the content above, we also need to maintain the relationship between TLB entries and processes, which should be done through ASID. However, we can simplify here by clearing the entire TLB when switching address spaces, similar to x86. For this, you also need to implement `__am_tlb_clear()` (defined in `abstract-machine/am/src/mips32/nemu/vme.c`).

<!-- -->
<!-- > #### todo::在分页机制上运行用户进程
> 根据上述的讲义内容, 对创建用户进程的过程进行相应改动, 让用户进程在分页机制上成功运行.
> 如果你选择了mips32或riscv32, 请注意地址空间描述符在上下文结构体中的位置,
> 如果你不确定这一位置, 请根据PA3中的讲义内容检查你的代码实现.
>
> 为了测试实现的正确性, 我们先单独运行dummy(别忘记修改调度代码),
> 并先在`exit`的实现中调用`halt()`结束系统的运行,
> 这是因为让其它程序成功运行还需要进行一些额外的改动.
> 如果你的实现正确, 你会看到dummy程序最后输出GOOD TRAP的信息, 说明它确实在分页机制上成功运行了. -->

> #### todo::Run User Processes on the Paging Mechanism
> According to the content of the lecture above, make corresponding changes to the process of creating user processes to allow them to run successfully on the paging mechanism.
> If you chose mips32 or riscv32, pay attention to the position of the address space descriptor in the context structure. If you are not sure about this position, check your code implementation according to the lecture content from PA3.
>
> To test the correctness of the implementation, we first run the dummy program alone (don't forget to modify the scheduling code), and call `halt()` in the `exit` implementation to terminate the system. This is because running other programs successfully requires some additional changes.
> If your implementation is correct, you will see the dummy program output GOOD TRAP at the end, indicating that it has successfully run on the paging mechanism.

<!-- -->
<!-- > #### option::让DiffTest支持分页机制(2)
> 如果你选择的是riscv32, 为了让DiffTest机制正确地支持用户进程的运行, 你还需要:
> * 实现`M`和`U`两种特权级模式, 具体地
>   * 在NEMU中实现`mstatus.MPP`位的功能
>   * 执行`ecall`指令时, 根据当前特权级抛出不同号码的异常, 但在CTE中对它们进行统一的处理
>   * 创建内核线程上下文时, 额外将`mstatus.MPP`设置为`M`模式
>   * 创建用户进程上下文时, 额外将`mstatus.MPP`设置为`U`模式
> * 填写页表时, 需要额外设置`R`, `W`, `X`, `U`, `A`, `D`位
> * 创建用户进程上下文时, 为`mstatus`额外设置`MXR`和`SUM`位 -->

> #### option::Enable DiffTest to Support Paging Mechanism (2)
> If you chose riscv32, to allow the DiffTest mechanism to correctly support the operation of user processes, you also need to:
> * Implement `M` and `U` privilege modes, specifically:
>   * Implement the functionality of the `mstatus.MPP` bit in NEMU
>   * When executing the `ecall` instruction, throw different exceptions based on the current privilege level, but handle them uniformly in the CTE
>   * When creating the kernel thread context, additionally set `mstatus.MPP` to `M` mode
>   * When creating the user process context, additionally set `mstatus.MPP` to `U` mode
> * When filling the page table, additionally set the `R`, `W`, `X`, `U`, `A`, and `D` bits
> * When creating the user process context, additionally set the `MXR` and `SUM` bits in `mstatus`

<!-- -->
<!-- > #### question::内核映射的作用
> 对于x86和riscv32, 在`protect()`中创建地址空间的时候, 有一处代码用于拷贝内核映射:
> ```c
> // map kernel space
> memcpy(updir, kas.ptr, PGSIZE);
> ```
> 尝试注释这处代码, 重新编译并运行, 你会看到发生了错误.
> 请解释为什么会发生这个错误. -->

> #### question::Role of Kernel Mapping
> For x86 and riscv32, when creating an address space in `protect()`, there is a piece of code used to copy the kernel mapping:
> ```c
> // map kernel space
> memcpy(updir, kas.ptr, PGSIZE);
> ```
> Try commenting out this code, recompile, and run the program. You will see an error occurs.
> Please explain why this error occurs.

<!-- 为了在分页机制上运行仙剑奇侠传, 我们还需要考虑堆区的问题.
之前我们让`mm_brk()`函数直接返回`0`, 表示用户进程的堆区大小修改总是成功,
这是因为在实现分页机制之前, `0x3000000`/`0x83000000`之上的内存都可以让用户进程自由使用.
现在用户进程运行在分页机制之上, 我们还需要在`mm_brk()`中把新申请的堆区映射到虚拟地址空间中,
这样才能保证运行在分页机制上的用户进程可以正确地访问新申请的堆区. -->

To run Chinese Paladin on the paging mechanism, we also need to consider the heap area. Previously, we let the `mm_brk()` function return `0` directly, indicating that the size modification of the user process's heap area was always successful. This was because before implementing the paging mechanism, memory above `0x3000000`/`0x83000000` could be freely used by the user process. Now that the user process is running on the paging mechanism, we need to map the newly allocated heap area into the virtual address space in `mm_brk()`. This ensures that the user process running on the paging mechanism can correctly access the newly allocated heap area.

<!-- 为了识别堆区中的哪些空间是新申请的, 我们还需要记录堆区的位置.
由于每个进程的堆区使用情况是独立的, 我们需要为它们分别维护堆区的位置,
因此我们在PCB中添加成员`max_brk`, 来记录program break曾经达到的最大位置.
引入`max_brk`是为了简化实现: 我们可以不实现堆区的回收功能,
而是只为当前新program break超过`max_brk`部分的虚拟地址空间分配物理页. -->

To identify which space in the heap area is newly allocated, we also need to record the position of the heap area. Since each process's heap usage is independent, we need to maintain the heap position separately for each process. Therefore, we add a member `max_brk` in the PCB to record the maximum position that the program break has ever reached. Introducing `max_brk` simplifies the implementation: we can avoid implementing the heap reclamation function and instead only allocate physical pages for the virtual address space portion where the new program break exceeds `max_brk`.

<!-- > #### todo::在分页机制上运行仙剑奇侠传
> 根据上述内容, 实现`nanos-lite/src/mm.c`中的`mm_brk()`函数.
> 你需要注意`map()`参数是否需要按页对齐的问题(这取决于你的`map()`实现).
>
> 实现正确后, 仙剑奇侠传就可以正确在分页机制上运行了. -->

> #### todo::Run Chinese Paladin on the Paging Mechanism
> Based on the content above, implement the `mm_brk()` function in `nanos-lite/src/mm.c`. You need to pay attention to whether the parameters of `map()` need to be page-aligned (this depends on your `map()` implementation).
>
> Once implemented correctly, Chinese Paladin will be able to run correctly on the paging mechanism.

<!-- -->
<!-- > #### comment::一致性问题 - mips32的噩梦来了
> 分页的道理也说得差不多了, 但如果你选择的是mips32,
> 在运行仙剑奇侠传的过程中, 你应该会遇到各种奇怪的问题,
> 而且不少问题可能都是一致性问题导致的.
> 在这里, TLB中的内容可以说是内存页表项的副本...
>
> 噢, 既然你有决心选择mips32, 我们就不透露那么多了,
> 尝试自己把这个问题理清楚, 并思考相应的解决方案吧.
> 解决了一致性问题, 才能说得上对mips32的分页机制有彻底的理解. -->

> #### comment::Consistency Issues - The Nightmare of mips32
> We've almost covered the principles of paging, but if you chose mips32, you might encounter various strange issues while running Chinese Paladin, many of which could be due to consistency problems.
> Here, the contents of the TLB can be considered as copies of the memory page table entries...
>
> Oh, since you have the determination to choose mips32, we won't reveal too much.
> Try to figure out this issue on your own and think about the corresponding solutions.
> Only after solving the consistency issue can you truly understand the paging mechanism of mips32.

<!-- -->
<!-- > #### option::支持声音
> 如果你之前实现了声卡相关的功能, 此时你可能会遇到错误.
> 尝试RTFSC并解决这个错误. -->

> #### option::Support Sound
> If you have previously implemented sound card-related functions, you might encounter errors at this point.
> Try to RTFSC (Read The Fabulous Source Code) and solve this error.

<!-- -->
<!-- > #### question::native的VME实现
> 尝试阅读`native`的VME实现, 你发现`native`是如何实现VME的? 为什么可以这样做? -->

> #### question::Native VME Implementation
> Try to read the VME implementation of `native`. How does `native` implement VME? Why can it be done this way?

<!-- -->
<!-- > #### question::可以在用户栈里面创建用户进程上下文吗?
> `ucontext()`的行为是在内核栈`kstack`中创建用户进程上下文.
> 我们是否可以对`ucontext()`的行为进行修改, 让它在用户栈上创建用户进程上下文? 为什么? -->

> #### question::Can User Process Contexts Be Created in the User Stack?
> The behavior of `ucontext()` is to create the user process context in the kernel stack `kstack`.
> Can we modify the behavior of `ucontext()` to create the user process context in the user stack? Why or why not?

<!-- ## 支持虚存管理的多道程序 -->

## Multi-programming with Virtual Memory Management

<!-- 绕了一大圈引入了虚存管理, 现在我们终于回来了: 我们可以支持多个用户进程的并发执行了.
不过我们还是先让运行在分页机制上的用户进程和内核线程并发执行, 来对分页机制进行进一步的测试. -->

After a long detour to introduce virtual memory management, we finally come back: we can now support the concurrent execution of multiple user processes. However, let's first allow user processes running on the paging mechanism to concurrently execute with kernel threads to further test the paging mechanism.

<!-- 为此, 我们需要思考内核线程的调度会对分页机制造成什么样的影响.
内核线程和用户进程最大的不同, 就是它没有用户态的地址空间:
内核线程的代码, 数据和栈都是位于内核的地址空间.
那在启动分页机制之后, 如果``__am_irq_handle()``要返回一个内核线程的现场,
我们是否需要考虑通过``__am_switch()``切换到内核线程的虚拟地址空间呢? -->

To do this, we need to consider how the scheduling of kernel threads will affect the paging mechanism. The biggest difference between kernel threads and user processes is that kernel threads do not have a user-mode address space: the code, data, and stack of kernel threads are all located in the kernel's address space. So, after enabling the paging mechanism, if `__am_irq_handle()` needs to return to a kernel thread's context, do we need to consider switching to the kernel thread's virtual address space using `__am_switch()`?

<!-- 答案是, 不需要. 这是因为AM创建的所有虚拟地址空间都会包含内核映射,
无论在切换之前是位于哪一个虚拟地址空间, 内核线程都可以在这个虚拟地址空间上正确运行.
因此我们只要在`kcontext()`中将上下文的地址空间描述符指针设置为`NULL`,
来进行特殊的标记, 等到将来在``__am_irq_handle()``中调用``__am_switch()``时,
如果发现地址空间描述符指针为`NULL`, 就不进行虚拟地址空间的切换. -->

The answer is no. This is because all virtual address spaces created by AM will include the kernel mapping. Regardless of which virtual address space was active before the switch, the kernel thread can run correctly in that virtual address space. Therefore, we only need to set the address space descriptor pointer of the context to `NULL` in `kcontext()` as a special marker. Later, when `__am_irq_handle()` calls `__am_switch()`, if it finds that the address space descriptor pointer is `NULL`, it will not perform the virtual address space switch.

<!-- > #### todo::支持虚存管理的多道程序
> 让Nanos-lite加载运行仙剑奇侠传和内核线程hello.
> 此时的运行效果和上一阶段一样, 但这次整个系统都是运行在分页机制之上的. -->

> #### todo::Multi-programming with Virtual Memory Management
> Enable Nanos-lite to load and run Chinese Paladin and the kernel thread hello.
> The running result should be the same as in the previous stage, but this time the entire system will be running on the paging mechanism.

<!-- 不过我们会发现, 和之前相比, 在分页机制上运行的仙剑奇侠传的性能有了明显的下降.
尽管NEMU在串行模拟MMU的功能, 并不能完全代表硬件MMU的真实运行情况,
但这也说明了虚存机制确实会带来额外的运行时开销.
由于这个原因, 60年代的工程师普遍对虚存机制有所顾虑, 不敢轻易在系统中实现虚存机制.
但"不必修改程序即可让多个程序并发运行"的好处越来越明显,
以至于虚存机制成为了现代计算机系统的标配. -->

However, we will find that compared to before, the performance of Chinese Paladin running on the paging mechanism has significantly decreased. Although NEMU serially simulates the MMU function and cannot fully represent the real operation of a hardware MMU, this also indicates that the virtual memory mechanism indeed incurs additional runtime overhead. For this reason, engineers in the 1960s were generally cautious about the virtual memory mechanism and did not easily implement it in their systems. However, the advantage of "allowing multiple programs to run concurrently without modifying the programs" became increasingly evident, leading to the virtual memory mechanism becoming a standard feature of modern computer systems.

<!-- > #### question::并发执行多个用户进程
> 让Nanos-lite加载仙剑奇侠传和hello这两个用户进程;
> 或者是加载NTerm和hello内核线程, 然后从NTerm启动仙剑奇侠传,
> 你应该会在运行的时候观察到错误.
> 尝试分析这一错误的原因, 并总结为了支持这一功能, 我们需要满足什么样的条件.
>
> 这可以说是一周目最难的一道思考题了, 虽然我们会在PA4的最后给出分析,
> 喜欢挑战的同学仍然可以在这里尝试独立思考: 如果你能独立解决这个问题,
> 说明你对计算机系统的理解可以说是相当了得了.
>
> Hint: 程序是个状态机. -->

> #### question::Concurrent Execution of Multiple User Processes
> Let Nanos-lite load both Chinese Paladin and the hello user process; or load NTerm and the hello kernel thread, and then start Chinese Paladin from NTerm. You are likely to observe errors during execution.
> Try to analyze the cause of these errors and summarize the conditions we need to meet to support this functionality.
>
> This can be considered the most challenging question in the first round. Although we will provide an analysis at the end of PA4, those who enjoy challenges can try to think independently here: if you can solve this problem on your own, it shows that your understanding of computer systems is quite remarkable.
>
> Hint: A program is a state machine.

<!-- 这一阶段的内容算是整个PA中最难的了, 连选做题的难度和之前比也不是一个量级的.
这也展示了构建系统的挑战: 随着一个系统趋于完善, 模块之间的交互会越来越复杂,
代码看似避繁就简却可谓字字珠玑, 牵一发而动全身.
不过这是项目复杂度上升的必然规律, 等到代码量到了一定程度,
即使是开发一个应用程序, 也会面临类似的困难.
那我们要如何理解和管理规模日趋复杂的项目代码呢? -->

This stage of the content is considered the most difficult in the entire PA, and even the difficulty of optional tasks is not on the same level as before. This also demonstrates the challenge of building systems: as a system becomes more complete, the interactions between modules become increasingly complex. The code may seem simplified, but every word is crucial, and a small change can affect the entire system. However, this is an inevitable rule of rising project complexity. When the codebase reaches a certain size, even developing an application can face similar difficulties. So how should we understand and manage increasingly complex project code?

<!-- 答案是抽象.
所以你在PA中看到各种各样的API, 我们并不是随随便便定义它们的,
它们确实蕴含了模块行为的本质, 从而帮助我们更容易地从宏观的角度理解整个系统的行为,
就算是调试, 这些API对我们梳理代码的行为也有巨大的帮助.
当你在理解, 实现, 调试这些API的过程中, 你对整个系统的认识也会越来越深刻.
如果你确实独立完成到这里, 就算你以后面对更复杂的项目, 相信你也不会畏惧了. -->

The answer is abstraction. That’s why you see various APIs in the PA; we do not define them arbitrarily. They indeed encapsulate the essence of module behavior, helping us understand the behavior of the entire system from a macro perspective more easily. Even when debugging, these APIs greatly assist us in organizing the behavior of the code. As you understand, implement, and debug these APIs, your understanding of the entire system will become more profound. If you indeed complete this independently, you will not be intimidated by more complex projects in the future.

<!-- > #### hint::温馨提示
> PA4阶段2到此结束. -->

> #### hint::Tips
> Stage 2 of PA4 ends here.
